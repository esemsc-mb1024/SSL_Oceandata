{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffeff24b",
   "metadata": {},
   "source": [
    "Initial CNN archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b86357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb7f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Dataset for .npy SAR images ---\n",
    "class NPYContrastiveDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.file_paths = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npy')])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.file_paths[idx]).astype(np.float32)\n",
    "        arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "        arr = np.expand_dims(arr, axis=0)  # [1, H, W]\n",
    "        img = torch.from_numpy(arr)\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img)\n",
    "        return img, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232b7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial CNN model placeholder\n",
    "class simple_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.p1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.c2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.p2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.c3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.p3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.c1(x))\n",
    "        x = self.p1(x)\n",
    "        x = self.act(self.c2(x))\n",
    "        x = self.p2(x)  \n",
    "        x = self.act(self.c3(x))\n",
    "        x = self.p3(x)\n",
    "        x = self.avg(x)\n",
    "        return x.view(x.size(0), -1)  # Flatten the output\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0169ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation placeholder \n",
    "class contrastive_transforms:\n",
    "    def __init__(self):\n",
    "        self.transform = nn.Identity([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomRotation(10),\n",
    "            T.RandomResizedCrop(32),\n",
    "            T.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5,), (0.5,))   # need to normalise custom dataset to have mean 0 and std 1\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):   # calls the funtion when an instance of the class is called\n",
    "        return self.transform(x), self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866a9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Custom Dataset ---\n",
    "folder = r\"C:\\Users\\Matthew.Barrett\\Downloads\\test_data\\sigma0_arrays\"\n",
    "train_dataset = NPYContrastiveDataset(folder_path=folder, transform=contrastive_transforms())\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d014bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial SimCLR model placeholder\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, out_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe2d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial loss function placeholder\n",
    "\n",
    "# --- NT-Xent Loss ---\n",
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    z = torch.cat([z_i, z_j], dim=0)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    similarity_matrix = torch.matmul(z, z.T)\n",
    "\n",
    "    batch_size = z_i.shape[0]\n",
    "    labels = torch.arange(batch_size).to(z.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool).to(z.device)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(2 * batch_size, -1)\n",
    "\n",
    "    positives = torch.exp(torch.sum(z_i * z_j, dim=-1) / temperature)\n",
    "    positives = torch.cat([positives, positives], dim=0)\n",
    "\n",
    "    denominator = torch.exp(similarity_matrix / temperature).sum(dim=-1)\n",
    "    loss = -torch.log(positives / denominator).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd65249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Setup ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimCLR(simple_cnn()).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0792f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "epochs = 1\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x_i, x_j) in enumerate(train_loader):\n",
    "        x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "        z_i = model(x_i)\n",
    "        z_j = model(x_j)\n",
    "\n",
    "        loss = nt_xent_loss(z_i, z_j)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(f\"  Batch {batch_idx+1}/{len(train_loader)} completed\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WV_setup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
